surveydata <- read.csv(here("data", "CompleteResponses.csv"))
#rename vars----
cln_surveydata <- surveydata %>%
clean_names %>%
rename(region = zipcode) %>% # old name = new name
rename(edu = elevel)
#verify var name changes
glimpse(cln_surveydata)
#CHANGE VAR dtypes----
#returns var data types
str(cln_surveydata)
#change dtype of edu, car, region predictor vars to factor
cln_surveydata$edu <- as.factor(cln_surveydata$edu)
cln_surveydata$car <- as.factor(cln_surveydata$car)
cln_surveydata$region <- as.factor(cln_surveydata$region)
#verify changes
glimpse(cln_surveydata)
#verify var name changes
glimpse(cln_surveydata)
#verify change
is.factor(cln_surveydata$brand)
#verify changes
glimpse(cln_surveydata)
#change dtype of target var to factor--need so R treats as classification problem
cln_surveydata$brand <- as.factor(cln_surveydata$brand)
#verify change
is.factor(cln_surveydata$brand)
set.seed(123)
#to create sample of dataset to work with: smple_name <- df[sample(1:nrow(df), replace = FALSE),]
#create/specify partition of 75/25 (p = .75), list = FALSE to create vector, not list
in_train <- createDataPartition(cln_surveydata$brand,
p = .75,
list = FALSE)
#use partition to create training dataset--[intraining,] tells R to use all columns when creating the training data
train_data <- cln_surveydata[in_train,]
#use partition to create testing dataset
test_data <- cln_surveydata[-in_train,]
#set up cross validation method with 3 folds to use for training the model
crossval_fit <- trainControl(method = "repeatedcv",
number = 3,
repeats = 1)
pcluster <- makeCluster(3, type = "SOCK")
#register cluster so that caret will know to train in parallel
registerDoSNOW(pcluster)
#TRAIN & TUNE RF MODEL----
#train basic random forest model, use wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = training_data,
method = "rf",
trControl = crossval_fit,
tunelength = 5))
#train basic random forest model, use wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = crossval_fit,
tunelength = 5))
rf_fit1
#train basic random forest model, wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
#setup 3-fold cross validation method to use for training the model
control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5,
savePredictions = TRUE,
verboseIter = TRUE)
#train basic random forest model, wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
rf_fit1
#setup parameter tuning grid FOR MANUAL TUNING ONLY
grid <- expand.grid(size = c(2,7,12,18,24,34),
k = c(1,2,3,4,5))
#train & manual tune random forest model
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = grid))
rf_fit1
#use rf_fit1 to predict brand preferences for obs in the testing_data
(pred_rf_fit1 <- predict(rf_fit1, test_data))
#view confusion matrix to est model performance on test data
(perform_rf_fit1 <- confusionMatrix(pred_rf_fit1,
test_data$brand))
#calculates importance of predictor vars
varImp(rf_fit1)
#plot brand vs. salary
plot_brand_salary <- cln_surveydata %>%
ggplot()+
geom_bar(x = brand, y = salary)
glimpse(cln_surveydata)
#plot brand vs. salary
plot_brand_salary <- cln_surveydata %>%
ggplot()+
geom_bar(aes(x = brand, y = salary))
View(plot_brand_salary)
#plot brand vs. salary
cln_surveydata %>%
ggplot()+
geom_bar(aes(x = brand, y = salary))
#plot brand vs. salary
cln_surveydata %>%
ggplot(aes(x = brand, y = salary))+
geom_bar()
#plot brand vs. salary
cln_surveydata %>%
group_by(salary) %>%
ggplot(aes(x = brand)) +
geom_bar()
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_bar()
#plot brand vs. salary
cln_surveydata %>%
ggplot(aes(x = salary, color = salary)) +
geom_point()
#plot brand vs. salary
cln_surveydata %>%
ggplot(aes(x = brand, y = salary)) +
geom_point()
cln_surveydata %>% count(salary)
hist(cln_surveydata$salary)
cln_surveydata %>% filter(brand)
#plot brand vs. salary
barplot(table(cln_surveydata$salary, cln_surveydata$brand))
#plot brand vs. salary
barplot(table(cln_surveydata$brand, cln_surveydata$salary))
#plot brand vs. salary
cln_surveydata %>%
cut(x = salary, breaks = 10) %>%
ggplot()+
geom_bar(aes(x = salary, y = brand))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(x = salary)+
geom_histogram(stat = "count")
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(stat = "count")
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(aes(y = stat(count)))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(aes(y = stat(count), bins = 10))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(aes(y = stat(count), stat_bin(10)))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(aes(stat = "count", stat_bin(10)))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(stat = "count", stat_bin(10))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot(aes(x = salary)) +
geom_histogram(stat_bin(10))
#plot brand vs. salary
cln_surveydata %>%
group_by(brand) %>%
ggplot() +
geom_histogram(aes(x = salary, stat_bin(10)))
#plot brand vs. salary
cln_surveydata %>%
ggplot(aes(x = brand, y = salary)) +
geom_violin()
var_imp(rf_fit1)
varImp(rf_fit1)
#plot brand vs. age
cln_surveydata %>%
ggplot(aes(x = brand, y = age)) +
geom_violin()
#plot brand by credit
cln_surveydata %>%
ggplot(aes(x = brand, y = credit)) +
geom_violin()
debugSource('C:/Users/kpiat/Data Science Stuff/Course 3-Data Program/Customer Brand Preferences/scripts/c3t2-kp-brand-pref-preprocess-eda.R', encoding = 'UTF-8')
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
testing_data
(pred_rf_fit1 <- predict(rf_fit1, test_data))
(perform_rf_fit1 <- confusionMatrix(pred_rf_fit1,
test_data$brand))
glimpse(train_data)
system.time(rf_salaryfit<- train(brand~. -age -edu -car -region -credit,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
warnings()
#use rf_salaryfit to predict brand pref for the test_data
(pred_rf_salaryfit <- predict(rf_salaryfit, test_data))
#evaluate performance of rf_salaryfit using confusion matrix
perform_rf_salaryfit <- confusionMatrix(pred_rf_fit1,
test_data$brand)
View(perform_rf_fit1)
perform_rf_salaryfit
perform_rf_fit1
varImp(rf_salaryfit)
perform_rf_salaryfit <- confusionMatrix(pred_rf_salaryfit,
test_data$brand)
View(perform_rf_salaryfit)
rf_salaryfit
perform_rf_salaryfit
perform_rf_fit1
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control
))
#use gbm_fit1 to make predictions of testing_data
gbm_fit1_preds <- predict(gbm_fit1,
test_data)
#view confusion matrix to measure gbm model performance on test data
perform_gbm_fit1 <- confusionMatrix(gbm_fit1_preds,
test_data$brand)
perform_gbm_fit1
perform_rf_fit1
pred_rf_fit1
rf_fit1$votes
library(tidyverse)
library(here)
library(janitor)
library(skimr)
library(generics)
#ran in console--install.packages("caret", dependencies = c("Depends", "Suggests"))
library(caret)
library(C50)
#library(doSNOW) #enables doing training in parallel
# library(gbm) #need to get var importance for gbm model
#read in training dataset
surveydata <- read.csv(here("data", "CompleteResponses.csv"))
cln_surveydata <- surveydata %>%
clean_names %>%
rename(region = zipcode) %>% # old name = new name
rename(edu = elevel)
cln_surveydata$edu <- as.factor(cln_surveydata$edu)
cln_surveydata$car <- as.factor(cln_surveydata$car)
cln_surveydata$region <- as.factor(cln_surveydata$region)
#change target var to factor--so treated as classification
cln_surveydata$brand <- as.factor(cln_surveydata$brand)
glimpse(cln_surveydata)
control <- trainControl(method = "repeatedcv",
number = 5,
repeats = 5)
library(doSNOW) #enables doing training in parallel
#use makecluster (doSNOW) to tell R use parallel process
pcluster <- makeCluster(3, type = "SOCK")
#register cluster so R will know what to use for pp
registerDoSNOW(pcluster)
#train & auto-tune random forest model, wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
set.seed(123)
#specify partition of 75/25 (p = .75), list = FALSE to output vector, not list
in_train <- createDataPartition(cln_surveydata$brand,
p = .75,
list = FALSE)
#use partition to create training dataset--[intraining,] tells R to use all columns when creating the training data
train_data <- cln_surveydata[in_train,]
#use partition to create testing dataset
test_data <- cln_surveydata[-in_train,]
#train & auto-tune random forest model, wrapper to time training
system.time(rf_fit1 <- train(brand~.,
data = train_data,
method = "rf",
trControl = control,
tunelength = 5))
#use rf_fit1 to predict brand preferences for obs in the testing_data
(pred_rf_fit1 <- predict(rf_fit1, test_data))
#view confusion matrix to est model performance on test data
(perform_rf_fit1 <- confusionMatrix(pred_rf_fit1,
test_data$brand))
#train a GBM (gradient boosting) model on the training_data, 3-fold crossval, w/ system.time wrapper
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control
))
#use gbm_fit1 to make predictions of testing_data
preds_gbm_fit1 <- predict(gbm_fit1,
test_data)
preds_gbm_fit1
#view confusion matrix to measure gbm model performance on test data
(perform_gbm_fit1 <- confusionMatrix(gbm_fit1_preds,
test_data$brand))
#view confusion matrix to measure gbm model performance on test data
(perform_gbm_fit1 <- confusionMatrix(preds_gbm_fit1,
test_data$brand))
perform_rf_fit1
varImp(gbm_fit1)
# must load gbm pkg for varImp to run on gbm model
library(gbm)
#calculate the importance of each feature/predictor var
varImp(gbm_fit1)
######## VAR IMPORTANCE--RF----
#calculates importance of predictor vars
varImp(rf_fit1)
# train & tune GBM model using only salary var
system.time(gbm_salaryfit <- train(brand~. -age -edu -car -region -credit,
data = train_data,
method = "gbm",
trControl = control,
tunelength = 5))
# train & tune GBM model using only salary var
system.time(gbm_salaryfit <- train(brand~. -age -edu -car -region -credit,
data = train_data,
method = "gbm",
trControl = control))
#use gbm_salaryfit to predict brand pref for the test_data
(pred_gbm_salaryfit <- predict(gbm_salaryfit, test_data))
#evaluate performance of rf_salaryfit using confusion matrix
(perform_gbm_salaryfit <- confusionMatrix(pred_gbm_salaryfit,
test_data$brand))
# train & tune GBM model using only salary var
system.time(gbm_agefit <- train(brand~. -salary -edu -car -region -credit,
data = train_data,
method = "gbm",
trControl = control))
#use gbm_salaryfit to predict brand pref for the test_data
(pred_gbm_agefit <- predict(gbm_agefit, test_data))
#evaluate performance of rf_salaryfit using confusion matrix
(perform_gbm_agefit <- confusionMatrix(pred_gbm_agefit,
test_data$brand))
View(train_data)
# train & tune GBM model using only age var
system.time(gbm_agefit <- train(brand~. -salary -edu -car -region -credit,
data = train_data,
method = "gbm",
trControl = control))
summary(perform_rf_fit1)
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control))
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 1)
#train a GBM (gradient boosting) model on the training_data, 3-fold crossval, w/ system.time wrapper
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control,
train.fraction = 0.5))
#train a GBM (gradient boosting) model on the training_data, 3-fold crossval, w/ system.time wrapper
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control,
nTrain = 0.5))
#train a GBM (gradient boosting) model on the training_data, 3-fold crossval, w/ system.time wrapper
system.time(gbm_fit1 <- train(brand~.,
data = train_data,
method = "gbm",
trControl = control,
train.fraction = 0.5))
debugSource('C:/Users/kpiat/Data Science Stuff/Course 3-Data Program/Customer Brand Preferences/scripts/c3t2-kp-brand-pref-preprocess-eda.R', encoding = 'UTF-8')
debugSource('C:/Users/kpiat/Data Science Stuff/Course 3-Data Program/Customer Brand Preferences/scripts/c3t2-kp-brand-pref-preprocess-eda.R', encoding = 'UTF-8')
#read in training dataset
surveydata <- read.csv(here("data", "CompleteResponses.csv"))
#rename vars
cln_surveydata <- surveydata %>%
clean_names %>%
rename(region = zipcode) %>% # old name = new name
rename(edu = elevel)
#verify var name changes
glimpse(cln_surveydata)
#change predictor vars to factor dtype
cln_surveydata$edu <- as.factor(cln_surveydata$edu)
cln_surveydata$car <- as.factor(cln_surveydata$car)
cln_surveydata$region <- as.factor(cln_surveydata$region)
#verify changes
glimpse(cln_surveydata)
#change target var to factor--so treated as classification
cln_surveydata$brand <- as.factor(cln_surveydata$brand)
#verify change
is.factor(cln_surveydata$brand)
#set random number generator so same obs are used used in split every time--important for reproducibility
set.seed(123)
#specify partition of 75/25 (p = .75), list = FALSE to output vector, not list
in_train <- createDataPartition(cln_surveydata$brand,
p = .75,
list = FALSE)
#use partition to create training dataset--[intraining,] tells R to use all columns when creating the training data
train_data <- cln_surveydata[in_train,]
#use partition to create testing dataset
test_data <- cln_surveydata[-in_train,]
#setup 5-fold cross validation method train models
control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 1,
classProbs = TRUE)
debugSource('C:/Users/kpiat/Data Science Stuff/Course 3-Data Program/Customer Brand Preferences/scripts/c3t2-kp-brand-pref-preprocess-eda.R', encoding = 'UTF-8')
install.packages("doParallel")
library(parallel)
library(doParallel)
detectCores(lofical = TRUE)
detectCores(logical = TRUE)
perform_gbm_agefit
perform_gbm_fit1
perform_gbm_salaryfit
perform_rf_fit1
varImp(gbm_fit1)
View(train_data)
system.time(gbm_creditfit <- train(brand~. -salary -edu -car -region -age,
data = train_data,
method = "gbm",
trControl = control))
# predict brand pref for test_data
(pred_gbm_creditfit <- predict(gbm_creditfit, test_data))
#evaluate performance using confusion matrix
(perform_gbm_creditfit <- confusionMatrix(pred_gbm_creditfit,
test_data$brand))
# train & tune GBM model using only age and credit vars
system.time(gbm_agecredfit <- train(brand~. -edu -car -region -salary,
data = train_data,
method = "gbm",
trControl = control))
#use gbm_salaryfit to predict brand pref for the test_data
(pred_gbm_agecredfit <- predict(gbm_agecredfit, test_data))
#evaluate performance of rf_salaryfit using confusion matrix
(perform_gbm_agecredfit <- confusionMatrix(pred_gbm_agecredfit,
test_data$brand))
#AGE, SALARY, AND CREDIT ONLY
system.time(gbm_agecredsalfit <- train(brand~. -edu -car -region,
data = train_data,
method = "gbm",
trControl = control))
#use gbm_salaryfit to predict brand pref for the test_data
(pred_gbm_agecredsalfit <- predict(gbm_agecredsalfit, test_data))
#evaluate performance of rf_salaryfit using confusion matrix
(perform_gbm_agecredsalfit <- confusionMatrix(pred_gbm_agecredsalfit,
test_data$brand))
perform_gbm_fit1
#read in incomplete survey data
incompletesurveydata <- read.csv(here("data", "SurveyIncomplete.csv"))
glimpse(incompletesurveydata)
#clean var names and rename vars
incompletesurveydata <- incompletesurveydata %>%
clean_names(incompletesurveydata) %>%
rename(edu = elevel) %>%
rename(region = zipcode)
#clean var names and rename vars
incompletesurveydata <- incompletesurveydata %>%
clean_names() %>%
rename(edu = elevel) %>%    # new name = old name
rename(region = zipcode)
glimpse(incompletesurveydata)    #verify changes
#check for missing values
sum(is.na(incompletesurveydata))
#change var dtypes to factor
incompletesurveydata$edu <- as.factor(incompletesurveydata$edu)
#change var dtypes to factor
incompletesurveydata$edu <- as.factor(incompletesurveydata$edu) incompletesurveydata$car <- as.factor(incompletesurveydata$car)
incompletesurveydata$car <- as.factor(incompletesurveydata$car)
incompletesurveydata$region <- as.factor(incompletesurveydata$region)
incompletesurveydata$brand <- as.factor(incompletesurveydata$brand)
print(gbm_agecredsalfit$finalModel)
glimpse(incompletesurveydata)
View(test_data)
#use final model (gbm_agecredsalfit) to predict brand pref for entirely new dataset (incompletesurveydata)
pred_incompletedata <- predict(gbm_agecredsalfit,
newdata = incompletesurveydata)
#evaluate performance
(perform_incompletedata <- confusionMatrix(pred_incompletedata, incompletesurveydata$brand))
gbm_agecredsalfit$modelInfo
gbm_agecredsalfit$dots
gbm_agecredsalfit$finalModel
#load pkgs
library(tidyverse)
library(here)
library(janitor)
library(caret)
#read in data
current_products <- read.csv(here("data", "existingproductattributes2017.csv"))
#read in new products data
new_products <- read.csv(here("data", "newproductattributes2017.csv"))
#return list of vars in current products data
glimpse(current_products)
#examine vars in new product data
glimpse(new_products)
